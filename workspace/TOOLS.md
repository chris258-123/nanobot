# Available Tools

This document describes the tools available to nanobot.

## File Operations

### read_file
Read the contents of a file.
```
read_file(path: str) -> str
```

### write_file
Write content to a file (creates parent directories if needed).
```
write_file(path: str, content: str) -> str
```

### edit_file
Edit a file by replacing specific text.
```
edit_file(path: str, old_text: str, new_text: str) -> str
```

### list_dir
List contents of a directory.
```
list_dir(path: str) -> str
```

## Shell Execution

### exec
Execute a shell command and return output.
```
exec(command: str, working_dir: str = None) -> str
```

**Safety Notes:**
- Commands have a configurable timeout (default 60s)
- Dangerous commands are blocked (rm -rf, format, dd, shutdown, etc.)
- Output is truncated at 10,000 characters
- Optional `restrictToWorkspace` config to limit paths

## Web Access

### web_search
Search the web using Brave Search API.
```
web_search(query: str, count: int = 5) -> str
```

Returns search results with titles, URLs, and snippets. Requires `tools.web.search.apiKey` in config.

### web_fetch
Fetch and extract main content from a URL.
```
web_fetch(url: str, extractMode: str = "markdown", maxChars: int = 50000) -> str
```

**Notes:**
- Content is extracted using readability
- Supports markdown or plain text extraction
- Output is truncated at 50,000 characters by default

### zhipu_web_search
Search using Zhipu AI web search (optimized for Chinese content).
```
zhipu_web_search(query: str) -> str
```

Requires `tools.web.zhipuApiKey` in config.

## Browser Automation

### browser
**Control a headless browser for web automation and interaction.**

**âš ï¸ IMPORTANT: Use this tool when the user asks to open, visit, browse, screenshot, or interact with websites!**

```
browser(
    action: str,           # Required: open, snapshot, click, fill, type, screenshot, close, back, forward, reload, scroll
    target: str = None,    # URL for open, element ref (@e1) or selector for click/fill, file path for screenshot
    value: str = None,     # Text value for fill/type actions
    session: str = None,   # Session ID for multiple isolated browser instances
    profile: str = None    # Profile name for persistent state (cookies, localStorage)
) -> str
```

**When to use browser vs web_fetch:**
- Use `browser` when:
  - User asks to "æ‰“å¼€" (open), "è®¿é—®" (visit), "æµè§ˆ" (browse) a website
  - User asks to "æˆªå›¾" (screenshot), "æ‹ç…§" (take photo) of a page
  - Page requires JavaScript to render
  - Need to interact with page (click, fill forms, scroll)
  - Need screenshots of rendered page
  - Need to maintain session state
- Use `web_fetch` when:
  - Just need static HTML content
  - Faster and lighter weight

**Typical workflow:**
```python
# 1. Open a website
browser(action="open", target="https://github.com")

# 2. Get page structure with element references
browser(action="snapshot")
# Returns: heading "GitHub" [ref=e1], link "Sign in" [ref=e2], ...

# 3. Interact with elements using refs
browser(action="click", target="@e2")  # Click "Sign in" link

# 4. Fill forms
browser(action="fill", target="@e5", value="username")

# 5. Take screenshot
browser(action="screenshot", target="page.png")

# 6. Close browser
browser(action="close")
```

**Actions:**
- `open`: Open a URL
- `snapshot`: Get accessibility tree with element references (@e1, @e2, ...)
- `click`: Click an element (use @e1 refs from snapshot)
- `fill`: Fill an input field
- `type`: Type text with keyboard
- `screenshot`: Save screenshot to file
- `close`: Close browser session
- `back`, `forward`, `reload`: Navigation
- `scroll`: Scroll the page

**Notes:**
- Requires `agent-browser` CLI to be installed: `npm install -g agent-browser && agent-browser install`
- Element references (@e1, @e2) are easier than CSS selectors
- Use `session` parameter for multiple isolated browser instances
- Use `profile` parameter to persist cookies and login state across sessions
- Browser operations are slower than web_fetch but support full JavaScript and interaction

**Examples of when to use:**
- User: "æ‰“å¼€ GitHub" â†’ browser(action="open", target="https://github.com")
- User: "æˆªå›¾è¿™ä¸ªç½‘é¡µ" â†’ browser(action="screenshot", target="screenshot.png")
- User: "è®¿é—® example.com" â†’ browser(action="open", target="https://example.com")
- User: "åœ¨ Google æœç´¢" â†’ browser(action="open", target="https://google.com"), then snapshot, fill, click

## Communication

### message
Send a message to the user (used internally).
```
message(content: str, channel: str = None, chat_id: str = None) -> str
```

## Background Tasks

### spawn
Spawn a subagent to handle a task in the background.
```
spawn(task: str, label: str = None) -> str
```

Use for complex or time-consuming tasks that can run independently. The subagent will complete the task and report back when done.

## Scheduled Reminders (Cron)

Use the `exec` tool to create scheduled reminders with `nanobot cron add`:

### Set a recurring reminder
```bash
# Every day at 9am
nanobot cron add --name "morning" --message "Good morning! â˜€ï¸" --cron "0 9 * * *"

# Every 2 hours
nanobot cron add --name "water" --message "Drink water! ğŸ’§" --every 7200
```

### Set a one-time reminder
```bash
# At a specific time (ISO format)
nanobot cron add --name "meeting" --message "Meeting starts now!" --at "2025-01-31T15:00:00"
```

### Manage reminders
```bash
nanobot cron list              # List all jobs
nanobot cron remove <job_id>   # Remove a job
```

## Heartbeat Task Management

The `HEARTBEAT.md` file in the workspace is checked every 30 minutes.
Use file operations to manage periodic tasks:

### Add a heartbeat task
```python
# Append a new task
edit_file(
    path="HEARTBEAT.md",
    old_text="## Example Tasks",
    new_text="- [ ] New periodic task here\n\n## Example Tasks"
)
```

### Remove a heartbeat task
```python
# Remove a specific task
edit_file(
    path="HEARTBEAT.md",
    old_text="- [ ] Task to remove\n",
    new_text=""
)
```

### Rewrite all tasks
```python
# Replace the entire file
write_file(
    path="HEARTBEAT.md",
    content="# Heartbeat Tasks\n\n- [ ] Task 1\n- [ ] Task 2\n"
)
```

---

## Web Scraping with Crawlee

### Crawlee Scripts

Nanobot includes Crawlee scripts for advanced web scraping. Use the `exec` tool to run them.

**Location:** `scripts/crawlee/`

### crawl-url.js - çˆ¬å–å•ä¸ªURL

çˆ¬å–å•ä¸ªç½‘é¡µå¹¶æå–è¯¦ç»†ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æ–‡æœ¬ã€é“¾æ¥ã€å›¾ç‰‡ã€Metaä¿¡æ¯ï¼‰ã€‚

```bash
exec(command="node scripts/crawlee/crawl-url.js https://example.com output.json")
```

**è¾“å‡º:** JSONæ–‡ä»¶åŒ…å«é¡µé¢å®Œæ•´ä¿¡æ¯

### crawl-urls.js - æ‰¹é‡çˆ¬å–URLåˆ—è¡¨

æ‰¹é‡çˆ¬å–å¤šä¸ªURLã€‚

```bash
exec(command="node scripts/crawlee/crawl-urls.js https://site1.com https://site2.com --output results.json")
```

**è¾“å‡º:** JSONæ•°ç»„åŒ…å«æ‰€æœ‰é¡µé¢ä¿¡æ¯

### crawl-site.js - çˆ¬å–æ•´ä¸ªç½‘ç«™

é€’å½’çˆ¬å–ç½‘ç«™çš„å¤šä¸ªé¡µé¢ï¼ˆåŒåŸŸåï¼‰ã€‚

```bash
exec(command="node scripts/crawlee/crawl-site.js https://example.com --max-pages 20 --output site-data.json")
```

**å‚æ•°:**
- `--max-pages`: æœ€å¤§çˆ¬å–é¡µé¢æ•°ï¼ˆé»˜è®¤10ï¼‰
- `--output`: è¾“å‡ºæ–‡ä»¶å

### crawl-novel-chapter.js - çˆ¬å–å°è¯´ç« èŠ‚

ä¸“é—¨ç”¨äºçˆ¬å–å°è¯´ç« èŠ‚å†…å®¹ï¼Œæ”¯æŒJSONå’ŒMarkdownä¸¤ç§è¾“å‡ºæ ¼å¼ã€‚

```bash
# JSONæ ¼å¼è¾“å‡ºï¼ˆé»˜è®¤ï¼‰
exec(command="node scripts/crawlee/crawl-novel-chapter.js https://example.com/chapter1 chapter1.json")

# Markdownæ ¼å¼è¾“å‡ºï¼ˆæ¨èç”¨äºagentè®°å¿†ç³»ç»Ÿï¼‰
exec(command="node scripts/crawlee/crawl-novel-chapter.js https://example.com/chapter1 chapter1.md --format=markdown")
```

**å‚æ•°:**
- `<chapter_url>`: ç« èŠ‚URLï¼ˆå¿…éœ€ï¼‰
- `[output_file]`: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ®formatè‡ªåŠ¨å‘½åï¼‰
- `--format=json|markdown`: è¾“å‡ºæ ¼å¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤jsonï¼‰

**è¾“å‡ºæ ¼å¼å¯¹æ¯”:**

JSONæ ¼å¼ï¼š
```json
{
  "title": "ç¬¬ä¸€ç« ",
  "content": "ç« èŠ‚å†…å®¹...",
  "url": "https://...",
  "contentLength": 3591,
  "timestamp": "2026-02-11T01:35:18.000Z"
}
```

Markdownæ ¼å¼ï¼ˆæ¨èï¼‰ï¼š
```markdown
# ç¬¬ä¸€ç« 

ç« èŠ‚å†…å®¹...

---

**å…ƒæ•°æ®ï¼š**
- æ¥æºï¼šhttps://...
- å­—æ•°ï¼š3591 å­—ç¬¦
- çˆ¬å–æ—¶é—´ï¼š2026/2/11 01:35:18
```

**ä¸ºä»€ä¹ˆMarkdownæ ¼å¼æ›´é€‚åˆagentè®°å¿†ç³»ç»Ÿ:**
- LLMåŸç”Ÿæ”¯æŒMarkdownæ ¼å¼
- ä¸nanobotçš„MEMORY.mdç³»ç»Ÿä¸€è‡´
- ä¿ç•™æ–‡æœ¬è¯­ä¹‰ç»“æ„ï¼ˆæ ‡é¢˜ã€æ®µè½ï¼‰
- Tokenæ•ˆç‡æ›´é«˜ï¼ˆæ— JSONè½¬ä¹‰ï¼‰
- å¯ç›´æ¥è¿½åŠ åˆ°workspaceæ–‡ä»¶

**æ‰¹é‡çˆ¬å–å¤šä¸ªç« èŠ‚:**
```bash
# æ–¹æ³•1: ä½¿ç”¨bashå¾ªç¯çˆ¬å–æŒ‡å®šèŒƒå›´çš„ç« èŠ‚
exec(command="for i in {1..100}; do node scripts/crawlee/crawl-novel-chapter.js https://www.bqg518.cc/#/book/341/$i /home/chris/Desktop/novel_data/chapter_$i.md --format=markdown; sleep 1; done")

# æ–¹æ³•2: ä½¿ç”¨Pythonè„šæœ¬æ‰¹é‡è°ƒç”¨
exec(command="python3 -c \"
import subprocess
import time
for i in range(1, 101):
    url = f'https://www.bqg518.cc/#/book/341/{i}'
    output = f'/home/chris/Desktop/novel_data/chapter_{i}.md'
    subprocess.run(['node', 'scripts/crawlee/crawl-novel-chapter.js', url, output, '--format=markdown'])
    time.sleep(1)
\"")
```

**ä½¿ç”¨åœºæ™¯:**
- æ•°æ®é‡‡é›†å’Œåˆ†æ
- ç½‘ç«™å†…å®¹æå–
- ç«å“åˆ†æ
- å†…å®¹èšåˆ
- å°è¯´ç« èŠ‚é‡‡é›†ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰

**æ³¨æ„äº‹é¡¹:**
- Crawleeä¼šè‡ªåŠ¨å¤„ç†é€Ÿç‡é™åˆ¶
- å¤§é‡çˆ¬å–æ—¶æ³¨æ„å†…å­˜ä½¿ç”¨
- éµå®ˆç½‘ç«™robots.txtè§„åˆ™

è¯¦ç»†æ–‡æ¡£: `scripts/crawlee/README.md`

---

## Adding Custom Tools

To add custom tools:
1. Create a class that extends `Tool` in `nanobot/agent/tools/`
2. Implement `name`, `description`, `parameters`, and `execute`
3. Register it in `AgentLoop._register_default_tools()`
